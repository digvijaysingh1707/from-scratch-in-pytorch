{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "file_path = \"data/shakespear.txt\"\n",
    "with open(file_path) as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running for the first time, it is necessary to run\n",
    "```\n",
    "nltk.download()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:10000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_sents = [word_tokenize(t) for t in sent_tokenize(data)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for sent in words_in_sents:\n",
    "    vocab += sent\n",
    "\n",
    "vocab = list(set(vocab))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "total_sents = len(words_in_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 300\n",
    "\n",
    "# Generate Embedding and Context Matrices\n",
    "mat_emb = torch.randn(vocab_size, embedding_size, dtype=torch.float32, requires_grad=True, device=device)\n",
    "mat_ctx = torch.randn(vocab_size, embedding_size, dtype=torch.float32, requires_grad=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_mat_emb = mat_emb.clone().detach()\n",
    "copy_mat_ctx = mat_ctx.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at sentence: 10\n",
      "Currently at sentence: 20\n",
      "Currently at sentence: 30\n",
      "Currently at sentence: 40\n",
      "Currently at sentence: 50\n",
      "Currently at sentence: 60\n",
      "Currently at sentence: 70\n",
      "Currently at sentence: 80\n",
      "Currently at sentence: 90\n",
      "Currently at sentence: 100\n",
      "Currently at sentence: 110\n",
      "Currently at sentence: 120\n",
      "Currently at sentence: 130\n",
      "Currently at sentence: 140\n",
      "Currently at sentence: 150\n",
      "Currently at sentence: 160\n",
      "Currently at sentence: 170\n",
      "Currently at sentence: 180\n",
      "Currently at sentence: 190\n",
      "Currently at sentence: 200\n",
      "Currently at sentence: 210\n",
      "Currently at sentence: 220\n",
      "Currently at sentence: 230\n",
      "Currently at sentence: 240\n",
      "Currently at sentence: 250\n",
      "Currently at sentence: 260\n",
      "Currently at sentence: 270\n",
      "Currently at sentence: 280\n",
      "Currently at sentence: 290\n",
      "Currently at sentence: 300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [287], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39mif\u001b[39;00m neg_generated \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ctx_words:\n\u001b[1;32m     31\u001b[0m         neg_words\u001b[39m.\u001b[39mappend(neg_generated)\n\u001b[0;32m---> 33\u001b[0m X_neg \u001b[39m=\u001b[39m mat_ctx[[vocab\u001b[39m.\u001b[39;49mindex(word_) \u001b[39mfor\u001b[39;49;00m word_ \u001b[39min\u001b[39;49;00m neg_words]]\n\u001b[1;32m     34\u001b[0m Y_neg \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(\u001b[39mlen\u001b[39m(neg_words), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m     36\u001b[0m X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mconcat((X_ctx, X_neg), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "window_size = 5\n",
    "sneak_len = int(window_size/2)\n",
    "neg_sampling = 5\n",
    "\n",
    "# Define loss function \n",
    "lr = 0.5\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "dataset = {}\n",
    "\n",
    "curr_sent = 0\n",
    "for sent in words_in_sents:\n",
    "    curr_sent += 1\n",
    "    if len(sent) > 2:\n",
    "        for word_idx in range(len(sent)):\n",
    "            word_of_interest = sent[word_idx]\n",
    "            # dataset[sent[word_idx]] = []\n",
    "            ctx_words = []\n",
    "            for ctx_idx in range(len(sent)):\n",
    "                if ctx_idx != word_idx and abs(ctx_idx - word_idx) <= sneak_len:\n",
    "                    ctx_words.append(sent[ctx_idx])\n",
    "            \n",
    "            X_ctx = mat_ctx[[vocab.index(word_) for word_ in ctx_words]]\n",
    "            Y_ctx = torch.zeros(len(ctx_words), dtype=torch.float32, device=device)\n",
    "            \n",
    "            neg_words = []\n",
    "            while len(neg_words) < (neg_sampling * len(ctx_words)):\n",
    "                neg_generated = random.choice(vocab)\n",
    "                if neg_generated not in ctx_words:\n",
    "                    neg_words.append(neg_generated)\n",
    "            \n",
    "            X_neg = mat_ctx[[vocab.index(word_) for word_ in neg_words]]\n",
    "            Y_neg = torch.ones(len(neg_words), dtype=torch.float32, device=device)\n",
    "\n",
    "            X = torch.concat((X_ctx, X_neg), dim=0)\n",
    "            Y = torch.concat((Y_ctx, Y_neg), dim=0)\n",
    "\n",
    "            pred = (X @ mat_emb[vocab.index(word_of_interest)]).sigmoid()\n",
    "            loss = loss_function(pred, Y)\n",
    "            \n",
    "            # Update Embedding & Context Matrices\n",
    "            mat_ctx.grad = None\n",
    "            mat_emb.grad = None\n",
    "\n",
    "            loss.backward()\n",
    "            # print(mat_ctx.grad.flatten().nonzero())\n",
    "\n",
    "            # update params\n",
    "            with torch.no_grad():\n",
    "                mat_ctx -= lr * mat_ctx.grad\n",
    "                mat_emb -= lr * mat_emb.grad\n",
    "            d = lr * mat_ctx.grad\n",
    "    \n",
    "    if curr_sent % 10 == 0:\n",
    "        print(f\"Currently at sentence: {curr_sent}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c741f2e161574c3cb93bc7475ad46271fa01a2bf647187abe1b406a686238bfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
