{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a simple 2-layered GCN from scratch in Pytorch\n",
    "Associated Paper: https://arxiv.org/pdf/1609.02907.pdf\n",
    "Example Taken: 2-layered GCN on CORA Dataset\n",
    "\n",
    "_TODO: Modularize GCN class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/cora/\"\n",
    "edgelist = pd.read_csv(os.path.join(data_dir, \"cora.cites\"), sep='\\t', header=None, names=[\"target\", \"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers shape: (2708, 1435)\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"paper_id\"] + [f\"term_{idx}\" for idx in range(1433)] + [\"subject\"]\n",
    "papers = pd.read_csv(\n",
    "    os.path.join(data_dir, \"cora.content\"), sep=\"\\t\", header=None, names=column_names,\n",
    ")\n",
    "print(\"Papers shape:\", papers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper Index -> Id & Vice Verca\n",
    "paper_idx_to_id = {idx_: id_ for idx_, id_ in enumerate(list(set(papers[\"paper_id\"])))}\n",
    "\n",
    "# Paper Id -> Index\n",
    "paper_id_to_idx = {id_: idx_ for idx_, id_ in paper_idx_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Normalized Adjacency Matrix -> A_HAT\n",
    "\n",
    "# Create an empty Adjacency matrix\n",
    "A = torch.zeros(papers.shape[0], papers.shape[0])\n",
    "\n",
    "# Fill the adjacency matrix wherever there is an edge\n",
    "for pair in edgelist.values:\n",
    "    A[paper_id_to_idx[pair[0]], paper_id_to_idx[pair[1]]] = 1\n",
    "\n",
    "# Create an Identity Matrix for A\n",
    "I = torch.eye(A.shape[0])\n",
    "\n",
    "# A_TILDA = A + I\n",
    "A_TILDA = A + I\n",
    "\n",
    "# Create the Inverse Squared Diagonal Matrix of A_TILDA\n",
    "D_TILDA_INVERSE_SQUARED = torch.zeros_like(A_TILDA)\n",
    "\n",
    "for i in range(len(A_TILDA)):\n",
    "    D_TILDA_INVERSE_SQUARED[i, i] = A_TILDA[i].sum().pow(-0.5)\n",
    "\n",
    "# Finally A_HAT = D_TILDA_INVERSE_SQUARED @ A_TILDA @ D_TILDA_INVERSE_SQUARED\n",
    "A_HAT = D_TILDA_INVERSE_SQUARED @ A_TILDA @ D_TILDA_INVERSE_SQUARED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 2708])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a two layered GCN model\n",
    "A_HAT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE X & Y: Preparing Dataset\n",
    "dataset = papers.values\n",
    "pairwise_indices = [x[0] for x in dataset]\n",
    "X_PRE = []\n",
    "Y_PRE = []\n",
    "for i in range(len(dataset)):\n",
    "    idx_ = pairwise_indices.index(paper_idx_to_id[i])    \n",
    "    X_PRE.append(list(dataset[idx_][1:-1]))\n",
    "    Y_PRE.append(dataset[idx_][-1])\n",
    "\n",
    "X = torch.tensor(X_PRE, dtype=torch.float32)\n",
    "\n",
    "# Convert Y to Onehot\n",
    "\n",
    "y_idx_to_label = {idx_: label_ for idx_, label_ in enumerate(set(Y_PRE))}\n",
    "y_label_to_idx = {label_: idx_ for idx_, label_ in y_idx_to_label.items()}\n",
    "\n",
    "Y_ONE_HOT = torch.zeros(len(Y_PRE), len(set(Y_PRE)))\n",
    "for idx_ in range(len(Y_PRE)):\n",
    "    row = torch.zeros(7)\n",
    "    row[y_label_to_idx[Y_PRE[idx_]]] = 1\n",
    "    Y_ONE_HOT[idx_] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model Weights\n",
    "feature_vector_size = X.shape[1]\n",
    "hidden_layer_size = 100\n",
    "output_size = len(set(Y_PRE))\n",
    "\n",
    "# Weights at layer 0, 1\n",
    "W_0 = torch.randn(feature_vector_size, hidden_layer_size, dtype=torch.float32, requires_grad=True)\n",
    "W_1 = torch.randn(hidden_layer_size, output_size, dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Model Loss: 5.46131706237793\n",
      "Epoch: 1; Model Loss: 5.405853271484375\n",
      "Epoch: 2; Model Loss: 5.351841449737549\n",
      "Epoch: 3; Model Loss: 5.299158573150635\n",
      "Epoch: 4; Model Loss: 5.247714519500732\n",
      "Epoch: 5; Model Loss: 5.1974263191223145\n",
      "Epoch: 6; Model Loss: 5.148350715637207\n",
      "Epoch: 7; Model Loss: 5.100292205810547\n",
      "Epoch: 8; Model Loss: 5.053269863128662\n",
      "Epoch: 9; Model Loss: 5.007540702819824\n",
      "Epoch: 10; Model Loss: 4.962957859039307\n",
      "Epoch: 11; Model Loss: 4.91948127746582\n",
      "Epoch: 12; Model Loss: 4.876903533935547\n",
      "Epoch: 13; Model Loss: 4.835084438323975\n",
      "Epoch: 14; Model Loss: 4.794074535369873\n",
      "Epoch: 15; Model Loss: 4.753962516784668\n",
      "Epoch: 16; Model Loss: 4.714903831481934\n",
      "Epoch: 17; Model Loss: 4.6767683029174805\n",
      "Epoch: 18; Model Loss: 4.639404296875\n",
      "Epoch: 19; Model Loss: 4.602801322937012\n",
      "Epoch: 20; Model Loss: 4.567200183868408\n",
      "Epoch: 21; Model Loss: 4.532393455505371\n",
      "Epoch: 22; Model Loss: 4.498125076293945\n",
      "Epoch: 23; Model Loss: 4.464578628540039\n",
      "Epoch: 24; Model Loss: 4.431486129760742\n",
      "Epoch: 25; Model Loss: 4.399092197418213\n",
      "Epoch: 26; Model Loss: 4.367538928985596\n",
      "Epoch: 27; Model Loss: 4.336609840393066\n",
      "Epoch: 28; Model Loss: 4.306213855743408\n",
      "Epoch: 29; Model Loss: 4.2761969566345215\n",
      "Epoch: 30; Model Loss: 4.246962547302246\n",
      "Epoch: 31; Model Loss: 4.218381404876709\n",
      "Epoch: 32; Model Loss: 4.19019079208374\n",
      "Epoch: 33; Model Loss: 4.16213321685791\n",
      "Epoch: 34; Model Loss: 4.134456634521484\n",
      "Epoch: 35; Model Loss: 4.107247829437256\n",
      "Epoch: 36; Model Loss: 4.0804643630981445\n",
      "Epoch: 37; Model Loss: 4.0543060302734375\n",
      "Epoch: 38; Model Loss: 4.0285420417785645\n",
      "Epoch: 39; Model Loss: 4.003158092498779\n",
      "Epoch: 40; Model Loss: 3.9781882762908936\n",
      "Epoch: 41; Model Loss: 3.953599691390991\n",
      "Epoch: 42; Model Loss: 3.9293453693389893\n",
      "Epoch: 43; Model Loss: 3.90535569190979\n",
      "Epoch: 44; Model Loss: 3.8817460536956787\n",
      "Epoch: 45; Model Loss: 3.8586180210113525\n",
      "Epoch: 46; Model Loss: 3.835829257965088\n",
      "Epoch: 47; Model Loss: 3.8134267330169678\n",
      "Epoch: 48; Model Loss: 3.79146671295166\n",
      "Epoch: 49; Model Loss: 3.7699525356292725\n",
      "Epoch: 50; Model Loss: 3.748817205429077\n",
      "Epoch: 51; Model Loss: 3.7281363010406494\n",
      "Epoch: 52; Model Loss: 3.7078070640563965\n",
      "Epoch: 53; Model Loss: 3.6877336502075195\n",
      "Epoch: 54; Model Loss: 3.668018102645874\n",
      "Epoch: 55; Model Loss: 3.64867901802063\n",
      "Epoch: 56; Model Loss: 3.629671812057495\n",
      "Epoch: 57; Model Loss: 3.611015796661377\n",
      "Epoch: 58; Model Loss: 3.5927226543426514\n",
      "Epoch: 59; Model Loss: 3.5748281478881836\n",
      "Epoch: 60; Model Loss: 3.5572991371154785\n",
      "Epoch: 61; Model Loss: 3.5400874614715576\n",
      "Epoch: 62; Model Loss: 3.5231382846832275\n",
      "Epoch: 63; Model Loss: 3.5064032077789307\n",
      "Epoch: 64; Model Loss: 3.489912271499634\n",
      "Epoch: 65; Model Loss: 3.4737420082092285\n",
      "Epoch: 66; Model Loss: 3.457995653152466\n",
      "Epoch: 67; Model Loss: 3.4426324367523193\n",
      "Epoch: 68; Model Loss: 3.4276015758514404\n",
      "Epoch: 69; Model Loss: 3.4128384590148926\n",
      "Epoch: 70; Model Loss: 3.3982532024383545\n",
      "Epoch: 71; Model Loss: 3.3839781284332275\n",
      "Epoch: 72; Model Loss: 3.3700051307678223\n",
      "Epoch: 73; Model Loss: 3.3563601970672607\n",
      "Epoch: 74; Model Loss: 3.342989921569824\n",
      "Epoch: 75; Model Loss: 3.329843759536743\n",
      "Epoch: 76; Model Loss: 3.3170228004455566\n",
      "Epoch: 77; Model Loss: 3.304507255554199\n",
      "Epoch: 78; Model Loss: 3.2922523021698\n",
      "Epoch: 79; Model Loss: 3.280142068862915\n",
      "Epoch: 80; Model Loss: 3.268292188644409\n",
      "Epoch: 81; Model Loss: 3.2566373348236084\n",
      "Epoch: 82; Model Loss: 3.245142698287964\n",
      "Epoch: 83; Model Loss: 3.2337236404418945\n",
      "Epoch: 84; Model Loss: 3.2224838733673096\n",
      "Epoch: 85; Model Loss: 3.2114510536193848\n",
      "Epoch: 86; Model Loss: 3.200615167617798\n",
      "Epoch: 87; Model Loss: 3.1899077892303467\n",
      "Epoch: 88; Model Loss: 3.1794044971466064\n",
      "Epoch: 89; Model Loss: 3.169079542160034\n",
      "Epoch: 90; Model Loss: 3.1588730812072754\n",
      "Epoch: 91; Model Loss: 3.1487314701080322\n",
      "Epoch: 92; Model Loss: 3.138709783554077\n",
      "Epoch: 93; Model Loss: 3.1288435459136963\n",
      "Epoch: 94; Model Loss: 3.1191580295562744\n",
      "Epoch: 95; Model Loss: 3.109649181365967\n",
      "Epoch: 96; Model Loss: 3.100332021713257\n",
      "Epoch: 97; Model Loss: 3.091207981109619\n",
      "Epoch: 98; Model Loss: 3.082252264022827\n",
      "Epoch: 99; Model Loss: 3.073458194732666\n",
      "Epoch: 100; Model Loss: 3.064786672592163\n",
      "Epoch: 101; Model Loss: 3.0562291145324707\n",
      "Epoch: 102; Model Loss: 3.047776937484741\n",
      "Epoch: 103; Model Loss: 3.0394411087036133\n",
      "Epoch: 104; Model Loss: 3.0312724113464355\n",
      "Epoch: 105; Model Loss: 3.0232484340667725\n",
      "Epoch: 106; Model Loss: 3.015277624130249\n",
      "Epoch: 107; Model Loss: 3.0073800086975098\n",
      "Epoch: 108; Model Loss: 2.9995057582855225\n",
      "Epoch: 109; Model Loss: 2.9917616844177246\n",
      "Epoch: 110; Model Loss: 2.9841575622558594\n",
      "Epoch: 111; Model Loss: 2.9766845703125\n",
      "Epoch: 112; Model Loss: 2.9692912101745605\n",
      "Epoch: 113; Model Loss: 2.961973190307617\n",
      "Epoch: 114; Model Loss: 2.954723358154297\n",
      "Epoch: 115; Model Loss: 2.947564125061035\n",
      "Epoch: 116; Model Loss: 2.94046688079834\n",
      "Epoch: 117; Model Loss: 2.9334402084350586\n",
      "Epoch: 118; Model Loss: 2.926509141921997\n",
      "Epoch: 119; Model Loss: 2.919529438018799\n",
      "Epoch: 120; Model Loss: 2.912656545639038\n",
      "Epoch: 121; Model Loss: 2.905914306640625\n",
      "Epoch: 122; Model Loss: 2.8992862701416016\n",
      "Epoch: 123; Model Loss: 2.892746925354004\n",
      "Epoch: 124; Model Loss: 2.8862693309783936\n",
      "Epoch: 125; Model Loss: 2.879878044128418\n",
      "Epoch: 126; Model Loss: 2.873560667037964\n",
      "Epoch: 127; Model Loss: 2.8673224449157715\n",
      "Epoch: 128; Model Loss: 2.8611114025115967\n",
      "Epoch: 129; Model Loss: 2.8548693656921387\n",
      "Epoch: 130; Model Loss: 2.8487040996551514\n",
      "Epoch: 131; Model Loss: 2.842557430267334\n",
      "Epoch: 132; Model Loss: 2.8364174365997314\n",
      "Epoch: 133; Model Loss: 2.83034348487854\n",
      "Epoch: 134; Model Loss: 2.8243825435638428\n",
      "Epoch: 135; Model Loss: 2.8185055255889893\n",
      "Epoch: 136; Model Loss: 2.8126893043518066\n",
      "Epoch: 137; Model Loss: 2.8069515228271484\n",
      "Epoch: 138; Model Loss: 2.8012821674346924\n",
      "Epoch: 139; Model Loss: 2.7956783771514893\n",
      "Epoch: 140; Model Loss: 2.7901391983032227\n",
      "Epoch: 141; Model Loss: 2.78467059135437\n",
      "Epoch: 142; Model Loss: 2.7792420387268066\n",
      "Epoch: 143; Model Loss: 2.7738776206970215\n",
      "Epoch: 144; Model Loss: 2.768585443496704\n",
      "Epoch: 145; Model Loss: 2.7633614540100098\n",
      "Epoch: 146; Model Loss: 2.758188247680664\n",
      "Epoch: 147; Model Loss: 2.753065347671509\n",
      "Epoch: 148; Model Loss: 2.7480175495147705\n",
      "Epoch: 149; Model Loss: 2.743028402328491\n",
      "Epoch: 150; Model Loss: 2.7380893230438232\n",
      "Epoch: 151; Model Loss: 2.7331383228302\n",
      "Epoch: 152; Model Loss: 2.7282536029815674\n",
      "Epoch: 153; Model Loss: 2.723400592803955\n",
      "Epoch: 154; Model Loss: 2.7185754776000977\n",
      "Epoch: 155; Model Loss: 2.7137973308563232\n",
      "Epoch: 156; Model Loss: 2.7090721130371094\n",
      "Epoch: 157; Model Loss: 2.7043802738189697\n",
      "Epoch: 158; Model Loss: 2.6997358798980713\n",
      "Epoch: 159; Model Loss: 2.6951141357421875\n",
      "Epoch: 160; Model Loss: 2.6905457973480225\n",
      "Epoch: 161; Model Loss: 2.6860125064849854\n",
      "Epoch: 162; Model Loss: 2.681516647338867\n",
      "Epoch: 163; Model Loss: 2.6770622730255127\n",
      "Epoch: 164; Model Loss: 2.672647714614868\n",
      "Epoch: 165; Model Loss: 2.6682791709899902\n",
      "Epoch: 166; Model Loss: 2.6639492511749268\n",
      "Epoch: 167; Model Loss: 2.659668445587158\n",
      "Epoch: 168; Model Loss: 2.6554410457611084\n",
      "Epoch: 169; Model Loss: 2.651233434677124\n",
      "Epoch: 170; Model Loss: 2.647083282470703\n",
      "Epoch: 171; Model Loss: 2.6429615020751953\n",
      "Epoch: 172; Model Loss: 2.6388723850250244\n",
      "Epoch: 173; Model Loss: 2.634833335876465\n",
      "Epoch: 174; Model Loss: 2.6308398246765137\n",
      "Epoch: 175; Model Loss: 2.626896858215332\n",
      "Epoch: 176; Model Loss: 2.6230053901672363\n",
      "Epoch: 177; Model Loss: 2.619155168533325\n",
      "Epoch: 178; Model Loss: 2.6153202056884766\n",
      "Epoch: 179; Model Loss: 2.611497640609741\n",
      "Epoch: 180; Model Loss: 2.6077194213867188\n",
      "Epoch: 181; Model Loss: 2.603987455368042\n",
      "Epoch: 182; Model Loss: 2.600288152694702\n",
      "Epoch: 183; Model Loss: 2.5966200828552246\n",
      "Epoch: 184; Model Loss: 2.592998743057251\n",
      "Epoch: 185; Model Loss: 2.5894107818603516\n",
      "Epoch: 186; Model Loss: 2.5858187675476074\n",
      "Epoch: 187; Model Loss: 2.5821917057037354\n",
      "Epoch: 188; Model Loss: 2.5786046981811523\n",
      "Epoch: 189; Model Loss: 2.5750622749328613\n",
      "Epoch: 190; Model Loss: 2.571575164794922\n",
      "Epoch: 191; Model Loss: 2.5681257247924805\n",
      "Epoch: 192; Model Loss: 2.564681053161621\n",
      "Epoch: 193; Model Loss: 2.5612752437591553\n",
      "Epoch: 194; Model Loss: 2.5578970909118652\n",
      "Epoch: 195; Model Loss: 2.5545451641082764\n",
      "Epoch: 196; Model Loss: 2.5512256622314453\n",
      "Epoch: 197; Model Loss: 2.54793119430542\n",
      "Epoch: 198; Model Loss: 2.544663190841675\n",
      "Epoch: 199; Model Loss: 2.5413811206817627\n",
      "Epoch: 200; Model Loss: 2.538133382797241\n",
      "Epoch: 201; Model Loss: 2.5349340438842773\n",
      "Epoch: 202; Model Loss: 2.5317330360412598\n",
      "Epoch: 203; Model Loss: 2.5285656452178955\n",
      "Epoch: 204; Model Loss: 2.525428295135498\n",
      "Epoch: 205; Model Loss: 2.5223207473754883\n",
      "Epoch: 206; Model Loss: 2.519235849380493\n",
      "Epoch: 207; Model Loss: 2.5161609649658203\n",
      "Epoch: 208; Model Loss: 2.513123035430908\n",
      "Epoch: 209; Model Loss: 2.510108470916748\n",
      "Epoch: 210; Model Loss: 2.507115125656128\n",
      "Epoch: 211; Model Loss: 2.5041491985321045\n",
      "Epoch: 212; Model Loss: 2.5012106895446777\n",
      "Epoch: 213; Model Loss: 2.4982995986938477\n",
      "Epoch: 214; Model Loss: 2.4954164028167725\n",
      "Epoch: 215; Model Loss: 2.492567539215088\n",
      "Epoch: 216; Model Loss: 2.4897446632385254\n",
      "Epoch: 217; Model Loss: 2.486950635910034\n",
      "Epoch: 218; Model Loss: 2.4841909408569336\n",
      "Epoch: 219; Model Loss: 2.4814608097076416\n",
      "Epoch: 220; Model Loss: 2.4787468910217285\n",
      "Epoch: 221; Model Loss: 2.4760379791259766\n",
      "Epoch: 222; Model Loss: 2.473355531692505\n",
      "Epoch: 223; Model Loss: 2.4707019329071045\n",
      "Epoch: 224; Model Loss: 2.4680657386779785\n",
      "Epoch: 225; Model Loss: 2.4654018878936768\n",
      "Epoch: 226; Model Loss: 2.46277117729187\n",
      "Epoch: 227; Model Loss: 2.4601659774780273\n",
      "Epoch: 228; Model Loss: 2.457583427429199\n",
      "Epoch: 229; Model Loss: 2.455024003982544\n",
      "Epoch: 230; Model Loss: 2.4524483680725098\n",
      "Epoch: 231; Model Loss: 2.4498989582061768\n",
      "Epoch: 232; Model Loss: 2.447376251220703\n",
      "Epoch: 233; Model Loss: 2.444885492324829\n",
      "Epoch: 234; Model Loss: 2.4424245357513428\n",
      "Epoch: 235; Model Loss: 2.4399924278259277\n",
      "Epoch: 236; Model Loss: 2.4375786781311035\n",
      "Epoch: 237; Model Loss: 2.4351649284362793\n",
      "Epoch: 238; Model Loss: 2.4327614307403564\n",
      "Epoch: 239; Model Loss: 2.43038272857666\n",
      "Epoch: 240; Model Loss: 2.4280107021331787\n",
      "Epoch: 241; Model Loss: 2.4256513118743896\n",
      "Epoch: 242; Model Loss: 2.423301935195923\n",
      "Epoch: 243; Model Loss: 2.4209728240966797\n",
      "Epoch: 244; Model Loss: 2.4186644554138184\n",
      "Epoch: 245; Model Loss: 2.416367769241333\n",
      "Epoch: 246; Model Loss: 2.4140899181365967\n",
      "Epoch: 247; Model Loss: 2.4118330478668213\n",
      "Epoch: 248; Model Loss: 2.409595251083374\n",
      "Epoch: 249; Model Loss: 2.407376766204834\n",
      "Epoch: 250; Model Loss: 2.405177354812622\n",
      "Epoch: 251; Model Loss: 2.402998924255371\n",
      "Epoch: 252; Model Loss: 2.4008400440216064\n",
      "Epoch: 253; Model Loss: 2.3987042903900146\n",
      "Epoch: 254; Model Loss: 2.3965871334075928\n",
      "Epoch: 255; Model Loss: 2.3944895267486572\n",
      "Epoch: 256; Model Loss: 2.392408847808838\n",
      "Epoch: 257; Model Loss: 2.3903212547302246\n",
      "Epoch: 258; Model Loss: 2.3882529735565186\n",
      "Epoch: 259; Model Loss: 2.3862051963806152\n",
      "Epoch: 260; Model Loss: 2.3841779232025146\n",
      "Epoch: 261; Model Loss: 2.3821702003479004\n",
      "Epoch: 262; Model Loss: 2.3801796436309814\n",
      "Epoch: 263; Model Loss: 2.378211498260498\n",
      "Epoch: 264; Model Loss: 2.37626576423645\n",
      "Epoch: 265; Model Loss: 2.374338150024414\n",
      "Epoch: 266; Model Loss: 2.372427225112915\n",
      "Epoch: 267; Model Loss: 2.370537042617798\n",
      "Epoch: 268; Model Loss: 2.3686654567718506\n",
      "Epoch: 269; Model Loss: 2.3668110370635986\n",
      "Epoch: 270; Model Loss: 2.364976644515991\n",
      "Epoch: 271; Model Loss: 2.363158702850342\n",
      "Epoch: 272; Model Loss: 2.361356496810913\n",
      "Epoch: 273; Model Loss: 2.3595728874206543\n",
      "Epoch: 274; Model Loss: 2.3578052520751953\n",
      "Epoch: 275; Model Loss: 2.356052875518799\n",
      "Epoch: 276; Model Loss: 2.354316234588623\n",
      "Epoch: 277; Model Loss: 2.352590322494507\n",
      "Epoch: 278; Model Loss: 2.3508689403533936\n",
      "Epoch: 279; Model Loss: 2.349163293838501\n",
      "Epoch: 280; Model Loss: 2.3474769592285156\n",
      "Epoch: 281; Model Loss: 2.3457837104797363\n",
      "Epoch: 282; Model Loss: 2.3441059589385986\n",
      "Epoch: 283; Model Loss: 2.342420816421509\n",
      "Epoch: 284; Model Loss: 2.3407511711120605\n",
      "Epoch: 285; Model Loss: 2.3390955924987793\n",
      "Epoch: 286; Model Loss: 2.3374552726745605\n",
      "Epoch: 287; Model Loss: 2.3358242511749268\n",
      "Epoch: 288; Model Loss: 2.3342013359069824\n",
      "Epoch: 289; Model Loss: 2.332594633102417\n",
      "Epoch: 290; Model Loss: 2.331002950668335\n",
      "Epoch: 291; Model Loss: 2.3294248580932617\n",
      "Epoch: 292; Model Loss: 2.3278605937957764\n",
      "Epoch: 293; Model Loss: 2.326303720474243\n",
      "Epoch: 294; Model Loss: 2.3247363567352295\n",
      "Epoch: 295; Model Loss: 2.3231709003448486\n",
      "Epoch: 296; Model Loss: 2.321620464324951\n",
      "Epoch: 297; Model Loss: 2.3200855255126953\n",
      "Epoch: 298; Model Loss: 2.318566083908081\n",
      "Epoch: 299; Model Loss: 2.317063331604004\n",
      "Epoch: 300; Model Loss: 2.3155763149261475\n",
      "Epoch: 301; Model Loss: 2.3141071796417236\n",
      "Epoch: 302; Model Loss: 2.312652826309204\n",
      "Epoch: 303; Model Loss: 2.3112106323242188\n",
      "Epoch: 304; Model Loss: 2.3097829818725586\n",
      "Epoch: 305; Model Loss: 2.3083667755126953\n",
      "Epoch: 306; Model Loss: 2.306960344314575\n",
      "Epoch: 307; Model Loss: 2.305546998977661\n",
      "Epoch: 308; Model Loss: 2.304145336151123\n",
      "Epoch: 309; Model Loss: 2.3027548789978027\n",
      "Epoch: 310; Model Loss: 2.3013763427734375\n",
      "Epoch: 311; Model Loss: 2.3000104427337646\n",
      "Epoch: 312; Model Loss: 2.298661231994629\n",
      "Epoch: 313; Model Loss: 2.2973270416259766\n",
      "Epoch: 314; Model Loss: 2.2960076332092285\n",
      "Epoch: 315; Model Loss: 2.2947018146514893\n",
      "Epoch: 316; Model Loss: 2.2934064865112305\n",
      "Epoch: 317; Model Loss: 2.292120933532715\n",
      "Epoch: 318; Model Loss: 2.290844678878784\n",
      "Epoch: 319; Model Loss: 2.2895679473876953\n",
      "Epoch: 320; Model Loss: 2.2882986068725586\n",
      "Epoch: 321; Model Loss: 2.2870285511016846\n",
      "Epoch: 322; Model Loss: 2.285767078399658\n",
      "Epoch: 323; Model Loss: 2.2844955921173096\n",
      "Epoch: 324; Model Loss: 2.2832250595092773\n",
      "Epoch: 325; Model Loss: 2.281964063644409\n",
      "Epoch: 326; Model Loss: 2.2807140350341797\n",
      "Epoch: 327; Model Loss: 2.279475450515747\n",
      "Epoch: 328; Model Loss: 2.278245687484741\n",
      "Epoch: 329; Model Loss: 2.277024745941162\n",
      "Epoch: 330; Model Loss: 2.2758126258850098\n",
      "Epoch: 331; Model Loss: 2.2746098041534424\n",
      "Epoch: 332; Model Loss: 2.2734174728393555\n",
      "Epoch: 333; Model Loss: 2.272233486175537\n",
      "Epoch: 334; Model Loss: 2.2710578441619873\n",
      "Epoch: 335; Model Loss: 2.2698910236358643\n",
      "Epoch: 336; Model Loss: 2.2687323093414307\n",
      "Epoch: 337; Model Loss: 2.267582416534424\n",
      "Epoch: 338; Model Loss: 2.266442060470581\n",
      "Epoch: 339; Model Loss: 2.265305995941162\n",
      "Epoch: 340; Model Loss: 2.2641775608062744\n",
      "Epoch: 341; Model Loss: 2.263054847717285\n",
      "Epoch: 342; Model Loss: 2.2619218826293945\n",
      "Epoch: 343; Model Loss: 2.2607743740081787\n",
      "Epoch: 344; Model Loss: 2.259636640548706\n",
      "Epoch: 345; Model Loss: 2.25850510597229\n",
      "Epoch: 346; Model Loss: 2.2573771476745605\n",
      "Epoch: 347; Model Loss: 2.2562575340270996\n",
      "Epoch: 348; Model Loss: 2.2551348209381104\n",
      "Epoch: 349; Model Loss: 2.2540197372436523\n",
      "Epoch: 350; Model Loss: 2.252912759780884\n",
      "Epoch: 351; Model Loss: 2.2518136501312256\n",
      "Epoch: 352; Model Loss: 2.250722885131836\n",
      "Epoch: 353; Model Loss: 2.2496402263641357\n",
      "Epoch: 354; Model Loss: 2.2485647201538086\n",
      "Epoch: 355; Model Loss: 2.247490882873535\n",
      "Epoch: 356; Model Loss: 2.246415853500366\n",
      "Epoch: 357; Model Loss: 2.2453508377075195\n",
      "Epoch: 358; Model Loss: 2.244295597076416\n",
      "Epoch: 359; Model Loss: 2.243251085281372\n",
      "Epoch: 360; Model Loss: 2.242213249206543\n",
      "Epoch: 361; Model Loss: 2.2411813735961914\n",
      "Epoch: 362; Model Loss: 2.2401554584503174\n",
      "Epoch: 363; Model Loss: 2.239135503768921\n",
      "Epoch: 364; Model Loss: 2.238121747970581\n",
      "Epoch: 365; Model Loss: 2.2371137142181396\n",
      "Epoch: 366; Model Loss: 2.236111640930176\n",
      "Epoch: 367; Model Loss: 2.2351155281066895\n",
      "Epoch: 368; Model Loss: 2.234126329421997\n",
      "Epoch: 369; Model Loss: 2.233140707015991\n",
      "Epoch: 370; Model Loss: 2.232154369354248\n",
      "Epoch: 371; Model Loss: 2.2311742305755615\n",
      "Epoch: 372; Model Loss: 2.2302005290985107\n",
      "Epoch: 373; Model Loss: 2.2292354106903076\n",
      "Epoch: 374; Model Loss: 2.2282750606536865\n",
      "Epoch: 375; Model Loss: 2.2273201942443848\n",
      "Epoch: 376; Model Loss: 2.2263710498809814\n",
      "Epoch: 377; Model Loss: 2.2254302501678467\n",
      "Epoch: 378; Model Loss: 2.2244949340820312\n",
      "Epoch: 379; Model Loss: 2.223569393157959\n",
      "Epoch: 380; Model Loss: 2.2226500511169434\n",
      "Epoch: 381; Model Loss: 2.221735954284668\n",
      "Epoch: 382; Model Loss: 2.2208259105682373\n",
      "Epoch: 383; Model Loss: 2.219921350479126\n",
      "Epoch: 384; Model Loss: 2.2190234661102295\n",
      "Epoch: 385; Model Loss: 2.218130111694336\n",
      "Epoch: 386; Model Loss: 2.2172417640686035\n",
      "Epoch: 387; Model Loss: 2.216357707977295\n",
      "Epoch: 388; Model Loss: 2.2154788970947266\n",
      "Epoch: 389; Model Loss: 2.214608669281006\n",
      "Epoch: 390; Model Loss: 2.2137439250946045\n",
      "Epoch: 391; Model Loss: 2.212883710861206\n",
      "Epoch: 392; Model Loss: 2.2120277881622314\n",
      "Epoch: 393; Model Loss: 2.211176872253418\n",
      "Epoch: 394; Model Loss: 2.2103323936462402\n",
      "Epoch: 395; Model Loss: 2.209491729736328\n",
      "Epoch: 396; Model Loss: 2.208655595779419\n",
      "Epoch: 397; Model Loss: 2.207822799682617\n",
      "Epoch: 398; Model Loss: 2.2069830894470215\n",
      "Epoch: 399; Model Loss: 2.2061469554901123\n",
      "Epoch: 400; Model Loss: 2.2053093910217285\n",
      "Epoch: 401; Model Loss: 2.204465866088867\n",
      "Epoch: 402; Model Loss: 2.203626871109009\n",
      "Epoch: 403; Model Loss: 2.202791929244995\n",
      "Epoch: 404; Model Loss: 2.2019622325897217\n",
      "Epoch: 405; Model Loss: 2.201139450073242\n",
      "Epoch: 406; Model Loss: 2.2003209590911865\n",
      "Epoch: 407; Model Loss: 2.1995046138763428\n",
      "Epoch: 408; Model Loss: 2.1986870765686035\n",
      "Epoch: 409; Model Loss: 2.197874069213867\n",
      "Epoch: 410; Model Loss: 2.1970646381378174\n",
      "Epoch: 411; Model Loss: 2.1962594985961914\n",
      "Epoch: 412; Model Loss: 2.195458173751831\n",
      "Epoch: 413; Model Loss: 2.194661855697632\n",
      "Epoch: 414; Model Loss: 2.193871021270752\n",
      "Epoch: 415; Model Loss: 2.1930837631225586\n",
      "Epoch: 416; Model Loss: 2.192301034927368\n",
      "Epoch: 417; Model Loss: 2.1915252208709717\n",
      "Epoch: 418; Model Loss: 2.1907541751861572\n",
      "Epoch: 419; Model Loss: 2.1899876594543457\n",
      "Epoch: 420; Model Loss: 2.189225673675537\n",
      "Epoch: 421; Model Loss: 2.1884679794311523\n",
      "Epoch: 422; Model Loss: 2.187714099884033\n",
      "Epoch: 423; Model Loss: 2.1869635581970215\n",
      "Epoch: 424; Model Loss: 2.1862175464630127\n",
      "Epoch: 425; Model Loss: 2.1854777336120605\n",
      "Epoch: 426; Model Loss: 2.184741973876953\n",
      "Epoch: 427; Model Loss: 2.184011459350586\n",
      "Epoch: 428; Model Loss: 2.1832783222198486\n",
      "Epoch: 429; Model Loss: 2.182549238204956\n",
      "Epoch: 430; Model Loss: 2.1818230152130127\n",
      "Epoch: 431; Model Loss: 2.181101083755493\n",
      "Epoch: 432; Model Loss: 2.1803829669952393\n",
      "Epoch: 433; Model Loss: 2.1796677112579346\n",
      "Epoch: 434; Model Loss: 2.1789562702178955\n",
      "Epoch: 435; Model Loss: 2.1782479286193848\n",
      "Epoch: 436; Model Loss: 2.177543878555298\n",
      "Epoch: 437; Model Loss: 2.1768434047698975\n",
      "Epoch: 438; Model Loss: 2.1761460304260254\n",
      "Epoch: 439; Model Loss: 2.1754517555236816\n",
      "Epoch: 440; Model Loss: 2.1747612953186035\n",
      "Epoch: 441; Model Loss: 2.1740777492523193\n",
      "Epoch: 442; Model Loss: 2.1733975410461426\n",
      "Epoch: 443; Model Loss: 2.1727206707000732\n",
      "Epoch: 444; Model Loss: 2.172048807144165\n",
      "Epoch: 445; Model Loss: 2.171377182006836\n",
      "Epoch: 446; Model Loss: 2.1707000732421875\n",
      "Epoch: 447; Model Loss: 2.1700263023376465\n",
      "Epoch: 448; Model Loss: 2.1693553924560547\n",
      "Epoch: 449; Model Loss: 2.168686866760254\n",
      "Epoch: 450; Model Loss: 2.1680221557617188\n",
      "Epoch: 451; Model Loss: 2.1673600673675537\n",
      "Epoch: 452; Model Loss: 2.1667003631591797\n",
      "Epoch: 453; Model Loss: 2.166043996810913\n",
      "Epoch: 454; Model Loss: 2.1653900146484375\n",
      "Epoch: 455; Model Loss: 2.1647398471832275\n",
      "Epoch: 456; Model Loss: 2.1640918254852295\n",
      "Epoch: 457; Model Loss: 2.1634490489959717\n",
      "Epoch: 458; Model Loss: 2.162809133529663\n",
      "Epoch: 459; Model Loss: 2.162172794342041\n",
      "Epoch: 460; Model Loss: 2.161539316177368\n",
      "Epoch: 461; Model Loss: 2.1609089374542236\n",
      "Epoch: 462; Model Loss: 2.1602814197540283\n",
      "Epoch: 463; Model Loss: 2.159656524658203\n",
      "Epoch: 464; Model Loss: 2.1590347290039062\n",
      "Epoch: 465; Model Loss: 2.1584155559539795\n",
      "Epoch: 466; Model Loss: 2.157794952392578\n",
      "Epoch: 467; Model Loss: 2.157168388366699\n",
      "Epoch: 468; Model Loss: 2.1565423011779785\n",
      "Epoch: 469; Model Loss: 2.1559107303619385\n",
      "Epoch: 470; Model Loss: 2.1552817821502686\n",
      "Epoch: 471; Model Loss: 2.1546571254730225\n",
      "Epoch: 472; Model Loss: 2.1540374755859375\n",
      "Epoch: 473; Model Loss: 2.1534206867218018\n",
      "Epoch: 474; Model Loss: 2.1528067588806152\n",
      "Epoch: 475; Model Loss: 2.152196168899536\n",
      "Epoch: 476; Model Loss: 2.1515917778015137\n",
      "Epoch: 477; Model Loss: 2.1509900093078613\n",
      "Epoch: 478; Model Loss: 2.150391101837158\n",
      "Epoch: 479; Model Loss: 2.149794816970825\n",
      "Epoch: 480; Model Loss: 2.1492013931274414\n",
      "Epoch: 481; Model Loss: 2.1486105918884277\n",
      "Epoch: 482; Model Loss: 2.1480231285095215\n",
      "Epoch: 483; Model Loss: 2.1474392414093018\n",
      "Epoch: 484; Model Loss: 2.146857976913452\n",
      "Epoch: 485; Model Loss: 2.1462793350219727\n",
      "Epoch: 486; Model Loss: 2.1457035541534424\n",
      "Epoch: 487; Model Loss: 2.1451308727264404\n",
      "Epoch: 488; Model Loss: 2.1445624828338623\n",
      "Epoch: 489; Model Loss: 2.143996238708496\n",
      "Epoch: 490; Model Loss: 2.1434333324432373\n",
      "Epoch: 491; Model Loss: 2.1428728103637695\n",
      "Epoch: 492; Model Loss: 2.142314910888672\n",
      "Epoch: 493; Model Loss: 2.1417596340179443\n",
      "Epoch: 494; Model Loss: 2.141206979751587\n",
      "Epoch: 495; Model Loss: 2.1406569480895996\n",
      "Epoch: 496; Model Loss: 2.1401097774505615\n",
      "Epoch: 497; Model Loss: 2.1395652294158936\n",
      "Epoch: 498; Model Loss: 2.1390228271484375\n",
      "Epoch: 499; Model Loss: 2.1384832859039307\n",
      "Epoch: 500; Model Loss: 2.1379480361938477\n",
      "Epoch: 501; Model Loss: 2.1374189853668213\n",
      "Epoch: 502; Model Loss: 2.136892318725586\n",
      "Epoch: 503; Model Loss: 2.1363677978515625\n",
      "Epoch: 504; Model Loss: 2.1358463764190674\n",
      "Epoch: 505; Model Loss: 2.1353256702423096\n",
      "Epoch: 506; Model Loss: 2.134800672531128\n",
      "Epoch: 507; Model Loss: 2.1342782974243164\n",
      "Epoch: 508; Model Loss: 2.1337602138519287\n",
      "Epoch: 509; Model Loss: 2.133244276046753\n",
      "Epoch: 510; Model Loss: 2.1327309608459473\n",
      "Epoch: 511; Model Loss: 2.1322193145751953\n",
      "Epoch: 512; Model Loss: 2.131702423095703\n",
      "Epoch: 513; Model Loss: 2.131188154220581\n",
      "Epoch: 514; Model Loss: 2.13067626953125\n",
      "Epoch: 515; Model Loss: 2.130167007446289\n",
      "Epoch: 516; Model Loss: 2.12965989112854\n",
      "Epoch: 517; Model Loss: 2.129155397415161\n",
      "Epoch: 518; Model Loss: 2.1286535263061523\n",
      "Epoch: 519; Model Loss: 2.1281535625457764\n",
      "Epoch: 520; Model Loss: 2.127652645111084\n",
      "Epoch: 521; Model Loss: 2.1271555423736572\n",
      "Epoch: 522; Model Loss: 2.1266605854034424\n",
      "Epoch: 523; Model Loss: 2.1261682510375977\n",
      "Epoch: 524; Model Loss: 2.125678062438965\n",
      "Epoch: 525; Model Loss: 2.125190019607544\n",
      "Epoch: 526; Model Loss: 2.124704599380493\n",
      "Epoch: 527; Model Loss: 2.1242215633392334\n",
      "Epoch: 528; Model Loss: 2.1237406730651855\n",
      "Epoch: 529; Model Loss: 2.123263359069824\n",
      "Epoch: 530; Model Loss: 2.1227898597717285\n",
      "Epoch: 531; Model Loss: 2.1223180294036865\n",
      "Epoch: 532; Model Loss: 2.1218488216400146\n",
      "Epoch: 533; Model Loss: 2.1213817596435547\n",
      "Epoch: 534; Model Loss: 2.1209168434143066\n",
      "Epoch: 535; Model Loss: 2.1204540729522705\n",
      "Epoch: 536; Model Loss: 2.1199939250946045\n",
      "Epoch: 537; Model Loss: 2.1195383071899414\n",
      "Epoch: 538; Model Loss: 2.1190857887268066\n",
      "Epoch: 539; Model Loss: 2.118635654449463\n",
      "Epoch: 540; Model Loss: 2.118187427520752\n",
      "Epoch: 541; Model Loss: 2.117741346359253\n",
      "Epoch: 542; Model Loss: 2.1172969341278076\n",
      "Epoch: 543; Model Loss: 2.1168549060821533\n",
      "Epoch: 544; Model Loss: 2.116414785385132\n",
      "Epoch: 545; Model Loss: 2.115976572036743\n",
      "Epoch: 546; Model Loss: 2.115540027618408\n",
      "Epoch: 547; Model Loss: 2.1151063442230225\n",
      "Epoch: 548; Model Loss: 2.114677667617798\n",
      "Epoch: 549; Model Loss: 2.114250898361206\n",
      "Epoch: 550; Model Loss: 2.1138253211975098\n",
      "Epoch: 551; Model Loss: 2.1133997440338135\n",
      "Epoch: 552; Model Loss: 2.1129753589630127\n",
      "Epoch: 553; Model Loss: 2.1125528812408447\n",
      "Epoch: 554; Model Loss: 2.1121325492858887\n",
      "Epoch: 555; Model Loss: 2.1117136478424072\n",
      "Epoch: 556; Model Loss: 2.111297369003296\n",
      "Epoch: 557; Model Loss: 2.1108827590942383\n",
      "Epoch: 558; Model Loss: 2.1104698181152344\n",
      "Epoch: 559; Model Loss: 2.1100587844848633\n",
      "Epoch: 560; Model Loss: 2.109649181365967\n",
      "Epoch: 561; Model Loss: 2.109241485595703\n",
      "Epoch: 562; Model Loss: 2.108835458755493\n",
      "Epoch: 563; Model Loss: 2.108431100845337\n",
      "Epoch: 564; Model Loss: 2.1080286502838135\n",
      "Epoch: 565; Model Loss: 2.1076276302337646\n",
      "Epoch: 566; Model Loss: 2.1072282791137695\n",
      "Epoch: 567; Model Loss: 2.106830358505249\n",
      "Epoch: 568; Model Loss: 2.1064348220825195\n",
      "Epoch: 569; Model Loss: 2.1060402393341064\n",
      "Epoch: 570; Model Loss: 2.105647563934326\n",
      "Epoch: 571; Model Loss: 2.1052565574645996\n",
      "Epoch: 572; Model Loss: 2.104867696762085\n",
      "Epoch: 573; Model Loss: 2.1044814586639404\n",
      "Epoch: 574; Model Loss: 2.1040971279144287\n",
      "Epoch: 575; Model Loss: 2.103714942932129\n",
      "Epoch: 576; Model Loss: 2.1033356189727783\n",
      "Epoch: 577; Model Loss: 2.1029582023620605\n",
      "Epoch: 578; Model Loss: 2.102581739425659\n",
      "Epoch: 579; Model Loss: 2.1022069454193115\n",
      "Epoch: 580; Model Loss: 2.1018340587615967\n",
      "Epoch: 581; Model Loss: 2.1014626026153564\n",
      "Epoch: 582; Model Loss: 2.101093053817749\n",
      "Epoch: 583; Model Loss: 2.100724697113037\n",
      "Epoch: 584; Model Loss: 2.100358009338379\n",
      "Epoch: 585; Model Loss: 2.0999929904937744\n",
      "Epoch: 586; Model Loss: 2.0996296405792236\n",
      "Epoch: 587; Model Loss: 2.0992672443389893\n",
      "Epoch: 588; Model Loss: 2.0989067554473877\n",
      "Epoch: 589; Model Loss: 2.0985469818115234\n",
      "Epoch: 590; Model Loss: 2.09818959236145\n",
      "Epoch: 591; Model Loss: 2.097834348678589\n",
      "Epoch: 592; Model Loss: 2.097480535507202\n",
      "Epoch: 593; Model Loss: 2.0971286296844482\n",
      "Epoch: 594; Model Loss: 2.0967776775360107\n",
      "Epoch: 595; Model Loss: 2.0964276790618896\n",
      "Epoch: 596; Model Loss: 2.0960755348205566\n",
      "Epoch: 597; Model Loss: 2.0957250595092773\n",
      "Epoch: 598; Model Loss: 2.09537672996521\n",
      "Epoch: 599; Model Loss: 2.095029830932617\n",
      "Epoch: 600; Model Loss: 2.094684362411499\n",
      "Epoch: 601; Model Loss: 2.0943400859832764\n",
      "Epoch: 602; Model Loss: 2.0939972400665283\n",
      "Epoch: 603; Model Loss: 2.0936551094055176\n",
      "Epoch: 604; Model Loss: 2.0933148860931396\n",
      "Epoch: 605; Model Loss: 2.0929758548736572\n",
      "Epoch: 606; Model Loss: 2.0926380157470703\n",
      "Epoch: 607; Model Loss: 2.092301368713379\n",
      "Epoch: 608; Model Loss: 2.091965675354004\n",
      "Epoch: 609; Model Loss: 2.0916318893432617\n",
      "Epoch: 610; Model Loss: 2.091299057006836\n",
      "Epoch: 611; Model Loss: 2.090968370437622\n",
      "Epoch: 612; Model Loss: 2.0906388759613037\n",
      "Epoch: 613; Model Loss: 2.0903103351593018\n",
      "Epoch: 614; Model Loss: 2.0899832248687744\n",
      "Epoch: 615; Model Loss: 2.0896573066711426\n",
      "Epoch: 616; Model Loss: 2.0893325805664062\n",
      "Epoch: 617; Model Loss: 2.0890095233917236\n",
      "Epoch: 618; Model Loss: 2.0886881351470947\n",
      "Epoch: 619; Model Loss: 2.0883688926696777\n",
      "Epoch: 620; Model Loss: 2.088047742843628\n",
      "Epoch: 621; Model Loss: 2.087728261947632\n",
      "Epoch: 622; Model Loss: 2.0874102115631104\n",
      "Epoch: 623; Model Loss: 2.087092638015747\n",
      "Epoch: 624; Model Loss: 2.086775302886963\n",
      "Epoch: 625; Model Loss: 2.086454391479492\n",
      "Epoch: 626; Model Loss: 2.086134672164917\n",
      "Epoch: 627; Model Loss: 2.0858166217803955\n",
      "Epoch: 628; Model Loss: 2.0854992866516113\n",
      "Epoch: 629; Model Loss: 2.0851833820343018\n",
      "Epoch: 630; Model Loss: 2.084869384765625\n",
      "Epoch: 631; Model Loss: 2.0845580101013184\n",
      "Epoch: 632; Model Loss: 2.0842483043670654\n",
      "Epoch: 633; Model Loss: 2.083939790725708\n",
      "Epoch: 634; Model Loss: 2.083631992340088\n",
      "Epoch: 635; Model Loss: 2.0833256244659424\n",
      "Epoch: 636; Model Loss: 2.0830202102661133\n",
      "Epoch: 637; Model Loss: 2.0827159881591797\n",
      "Epoch: 638; Model Loss: 2.0824127197265625\n",
      "Epoch: 639; Model Loss: 2.08211088180542\n",
      "Epoch: 640; Model Loss: 2.0818097591400146\n",
      "Epoch: 641; Model Loss: 2.081509828567505\n",
      "Epoch: 642; Model Loss: 2.0812110900878906\n",
      "Epoch: 643; Model Loss: 2.0809133052825928\n",
      "Epoch: 644; Model Loss: 2.0806169509887695\n",
      "Epoch: 645; Model Loss: 2.0803210735321045\n",
      "Epoch: 646; Model Loss: 2.0800273418426514\n",
      "Epoch: 647; Model Loss: 2.079735517501831\n",
      "Epoch: 648; Model Loss: 2.0794448852539062\n",
      "Epoch: 649; Model Loss: 2.079155683517456\n",
      "Epoch: 650; Model Loss: 2.0788681507110596\n",
      "Epoch: 651; Model Loss: 2.078582286834717\n",
      "Epoch: 652; Model Loss: 2.0782968997955322\n",
      "Epoch: 653; Model Loss: 2.0780129432678223\n",
      "Epoch: 654; Model Loss: 2.0777297019958496\n",
      "Epoch: 655; Model Loss: 2.0774476528167725\n",
      "Epoch: 656; Model Loss: 2.0771665573120117\n",
      "Epoch: 657; Model Loss: 2.0768864154815674\n",
      "Epoch: 658; Model Loss: 2.076608419418335\n",
      "Epoch: 659; Model Loss: 2.0763320922851562\n",
      "Epoch: 660; Model Loss: 2.0760529041290283\n",
      "Epoch: 661; Model Loss: 2.075774908065796\n",
      "Epoch: 662; Model Loss: 2.075498104095459\n",
      "Epoch: 663; Model Loss: 2.0752220153808594\n",
      "Epoch: 664; Model Loss: 2.074946880340576\n",
      "Epoch: 665; Model Loss: 2.0746729373931885\n",
      "Epoch: 666; Model Loss: 2.0744009017944336\n",
      "Epoch: 667; Model Loss: 2.074129819869995\n",
      "Epoch: 668; Model Loss: 2.073859691619873\n",
      "Epoch: 669; Model Loss: 2.0735902786254883\n",
      "Epoch: 670; Model Loss: 2.07332181930542\n",
      "Epoch: 671; Model Loss: 2.073054313659668\n",
      "Epoch: 672; Model Loss: 2.0727875232696533\n",
      "Epoch: 673; Model Loss: 2.0725221633911133\n",
      "Epoch: 674; Model Loss: 2.0722570419311523\n",
      "Epoch: 675; Model Loss: 2.071993350982666\n",
      "Epoch: 676; Model Loss: 2.071730375289917\n",
      "Epoch: 677; Model Loss: 2.071469306945801\n",
      "Epoch: 678; Model Loss: 2.07120943069458\n",
      "Epoch: 679; Model Loss: 2.0709502696990967\n",
      "Epoch: 680; Model Loss: 2.0706915855407715\n",
      "Epoch: 681; Model Loss: 2.070434093475342\n",
      "Epoch: 682; Model Loss: 2.0701775550842285\n",
      "Epoch: 683; Model Loss: 2.0699217319488525\n",
      "Epoch: 684; Model Loss: 2.069666862487793\n",
      "Epoch: 685; Model Loss: 2.0694124698638916\n",
      "Epoch: 686; Model Loss: 2.069159507751465\n",
      "Epoch: 687; Model Loss: 2.068906784057617\n",
      "Epoch: 688; Model Loss: 2.068655014038086\n",
      "Epoch: 689; Model Loss: 2.06840443611145\n",
      "Epoch: 690; Model Loss: 2.0681540966033936\n",
      "Epoch: 691; Model Loss: 2.0679049491882324\n",
      "Epoch: 692; Model Loss: 2.0676565170288086\n",
      "Epoch: 693; Model Loss: 2.067408800125122\n",
      "Epoch: 694; Model Loss: 2.067162036895752\n",
      "Epoch: 695; Model Loss: 2.06691575050354\n",
      "Epoch: 696; Model Loss: 2.0666706562042236\n",
      "Epoch: 697; Model Loss: 2.0664262771606445\n",
      "Epoch: 698; Model Loss: 2.0661826133728027\n",
      "Epoch: 699; Model Loss: 2.0659399032592773\n",
      "Epoch: 700; Model Loss: 2.065697431564331\n",
      "Epoch: 701; Model Loss: 2.0654563903808594\n",
      "Epoch: 702; Model Loss: 2.065215587615967\n",
      "Epoch: 703; Model Loss: 2.0649759769439697\n",
      "Epoch: 704; Model Loss: 2.064737558364868\n",
      "Epoch: 705; Model Loss: 2.0644989013671875\n",
      "Epoch: 706; Model Loss: 2.0642619132995605\n",
      "Epoch: 707; Model Loss: 2.0640251636505127\n",
      "Epoch: 708; Model Loss: 2.0637893676757812\n",
      "Epoch: 709; Model Loss: 2.0635547637939453\n",
      "Epoch: 710; Model Loss: 2.063321113586426\n",
      "Epoch: 711; Model Loss: 2.0630884170532227\n",
      "Epoch: 712; Model Loss: 2.0628573894500732\n",
      "Epoch: 713; Model Loss: 2.0626273155212402\n",
      "Epoch: 714; Model Loss: 2.0623974800109863\n",
      "Epoch: 715; Model Loss: 2.062168836593628\n",
      "Epoch: 716; Model Loss: 2.0619406700134277\n",
      "Epoch: 717; Model Loss: 2.061713218688965\n",
      "Epoch: 718; Model Loss: 2.0614876747131348\n",
      "Epoch: 719; Model Loss: 2.0612633228302\n",
      "Epoch: 720; Model Loss: 2.0610392093658447\n",
      "Epoch: 721; Model Loss: 2.0608153343200684\n",
      "Epoch: 722; Model Loss: 2.0605924129486084\n",
      "Epoch: 723; Model Loss: 2.060370445251465\n",
      "Epoch: 724; Model Loss: 2.0601484775543213\n",
      "Epoch: 725; Model Loss: 2.059927463531494\n",
      "Epoch: 726; Model Loss: 2.059706926345825\n",
      "Epoch: 727; Model Loss: 2.0594871044158936\n",
      "Epoch: 728; Model Loss: 2.05926775932312\n",
      "Epoch: 729; Model Loss: 2.059049129486084\n",
      "Epoch: 730; Model Loss: 2.058830976486206\n",
      "Epoch: 731; Model Loss: 2.0586135387420654\n",
      "Epoch: 732; Model Loss: 2.058396577835083\n",
      "Epoch: 733; Model Loss: 2.0581798553466797\n",
      "Epoch: 734; Model Loss: 2.057964324951172\n",
      "Epoch: 735; Model Loss: 2.057749032974243\n",
      "Epoch: 736; Model Loss: 2.0575342178344727\n",
      "Epoch: 737; Model Loss: 2.0573198795318604\n",
      "Epoch: 738; Model Loss: 2.0571062564849854\n",
      "Epoch: 739; Model Loss: 2.0568933486938477\n",
      "Epoch: 740; Model Loss: 2.0566813945770264\n",
      "Epoch: 741; Model Loss: 2.0564703941345215\n",
      "Epoch: 742; Model Loss: 2.0562596321105957\n",
      "Epoch: 743; Model Loss: 2.0560498237609863\n",
      "Epoch: 744; Model Loss: 2.055840253829956\n",
      "Epoch: 745; Model Loss: 2.055631160736084\n",
      "Epoch: 746; Model Loss: 2.0554230213165283\n",
      "Epoch: 747; Model Loss: 2.0552151203155518\n",
      "Epoch: 748; Model Loss: 2.0550074577331543\n",
      "Epoch: 749; Model Loss: 2.0548012256622314\n",
      "Epoch: 750; Model Loss: 2.054595470428467\n",
      "Epoch: 751; Model Loss: 2.0543837547302246\n",
      "Epoch: 752; Model Loss: 2.0541722774505615\n",
      "Epoch: 753; Model Loss: 2.053961992263794\n",
      "Epoch: 754; Model Loss: 2.0537526607513428\n",
      "Epoch: 755; Model Loss: 2.05354380607605\n",
      "Epoch: 756; Model Loss: 2.053335428237915\n",
      "Epoch: 757; Model Loss: 2.0531277656555176\n",
      "Epoch: 758; Model Loss: 2.0529205799102783\n",
      "Epoch: 759; Model Loss: 2.0527141094207764\n",
      "Epoch: 760; Model Loss: 2.0525076389312744\n",
      "Epoch: 761; Model Loss: 2.0523018836975098\n",
      "Epoch: 762; Model Loss: 2.0520968437194824\n",
      "Epoch: 763; Model Loss: 2.051892042160034\n",
      "Epoch: 764; Model Loss: 2.0516879558563232\n",
      "Epoch: 765; Model Loss: 2.0514843463897705\n",
      "Epoch: 766; Model Loss: 2.051281452178955\n",
      "Epoch: 767; Model Loss: 2.0510787963867188\n",
      "Epoch: 768; Model Loss: 2.0508763790130615\n",
      "Epoch: 769; Model Loss: 2.0506749153137207\n",
      "Epoch: 770; Model Loss: 2.050473213195801\n",
      "Epoch: 771; Model Loss: 2.0502724647521973\n",
      "Epoch: 772; Model Loss: 2.050071954727173\n",
      "Epoch: 773; Model Loss: 2.0498716831207275\n",
      "Epoch: 774; Model Loss: 2.0496718883514404\n",
      "Epoch: 775; Model Loss: 2.0494728088378906\n",
      "Epoch: 776; Model Loss: 2.04927396774292\n",
      "Epoch: 777; Model Loss: 2.0490756034851074\n",
      "Epoch: 778; Model Loss: 2.048877477645874\n",
      "Epoch: 779; Model Loss: 2.048679828643799\n",
      "Epoch: 780; Model Loss: 2.048482894897461\n",
      "Epoch: 781; Model Loss: 2.048285722732544\n",
      "Epoch: 782; Model Loss: 2.0480897426605225\n",
      "Epoch: 783; Model Loss: 2.047893762588501\n",
      "Epoch: 784; Model Loss: 2.0476980209350586\n",
      "Epoch: 785; Model Loss: 2.0475027561187744\n",
      "Epoch: 786; Model Loss: 2.0473082065582275\n",
      "Epoch: 787; Model Loss: 2.0471136569976807\n",
      "Epoch: 788; Model Loss: 2.046919822692871\n",
      "Epoch: 789; Model Loss: 2.0467259883880615\n",
      "Epoch: 790; Model Loss: 2.0465328693389893\n",
      "Epoch: 791; Model Loss: 2.046339988708496\n",
      "Epoch: 792; Model Loss: 2.046147584915161\n",
      "Epoch: 793; Model Loss: 2.0459554195404053\n",
      "Epoch: 794; Model Loss: 2.0457637310028076\n",
      "Epoch: 795; Model Loss: 2.045572519302368\n",
      "Epoch: 796; Model Loss: 2.045382022857666\n",
      "Epoch: 797; Model Loss: 2.0451931953430176\n",
      "Epoch: 798; Model Loss: 2.0450046062469482\n",
      "Epoch: 799; Model Loss: 2.044816493988037\n",
      "Epoch: 800; Model Loss: 2.044628620147705\n",
      "Epoch: 801; Model Loss: 2.044440746307373\n",
      "Epoch: 802; Model Loss: 2.0442538261413574\n",
      "Epoch: 803; Model Loss: 2.044067859649658\n",
      "Epoch: 804; Model Loss: 2.043882131576538\n",
      "Epoch: 805; Model Loss: 2.043696403503418\n",
      "Epoch: 806; Model Loss: 2.0435116291046143\n",
      "Epoch: 807; Model Loss: 2.0433268547058105\n",
      "Epoch: 808; Model Loss: 2.043142318725586\n",
      "Epoch: 809; Model Loss: 2.0429580211639404\n",
      "Epoch: 810; Model Loss: 2.042774200439453\n",
      "Epoch: 811; Model Loss: 2.042590618133545\n",
      "Epoch: 812; Model Loss: 2.042407512664795\n",
      "Epoch: 813; Model Loss: 2.042224407196045\n",
      "Epoch: 814; Model Loss: 2.042041778564453\n",
      "Epoch: 815; Model Loss: 2.0418593883514404\n",
      "Epoch: 816; Model Loss: 2.041677713394165\n",
      "Epoch: 817; Model Loss: 2.0414960384368896\n",
      "Epoch: 818; Model Loss: 2.0413146018981934\n",
      "Epoch: 819; Model Loss: 2.0411336421966553\n",
      "Epoch: 820; Model Loss: 2.040952682495117\n",
      "Epoch: 821; Model Loss: 2.040771961212158\n",
      "Epoch: 822; Model Loss: 2.0405921936035156\n",
      "Epoch: 823; Model Loss: 2.040411949157715\n",
      "Epoch: 824; Model Loss: 2.0402326583862305\n",
      "Epoch: 825; Model Loss: 2.040053367614746\n",
      "Epoch: 826; Model Loss: 2.039874315261841\n",
      "Epoch: 827; Model Loss: 2.039694309234619\n",
      "Epoch: 828; Model Loss: 2.039508581161499\n",
      "Epoch: 829; Model Loss: 2.0393238067626953\n",
      "Epoch: 830; Model Loss: 2.0391387939453125\n",
      "Epoch: 831; Model Loss: 2.038954257965088\n",
      "Epoch: 832; Model Loss: 2.0387699604034424\n",
      "Epoch: 833; Model Loss: 2.038586139678955\n",
      "Epoch: 834; Model Loss: 2.0384023189544678\n",
      "Epoch: 835; Model Loss: 2.038219451904297\n",
      "Epoch: 836; Model Loss: 2.0380373001098633\n",
      "Epoch: 837; Model Loss: 2.037855863571167\n",
      "Epoch: 838; Model Loss: 2.0376741886138916\n",
      "Epoch: 839; Model Loss: 2.0374929904937744\n",
      "Epoch: 840; Model Loss: 2.0373120307922363\n",
      "Epoch: 841; Model Loss: 2.0371317863464355\n",
      "Epoch: 842; Model Loss: 2.0369515419006348\n",
      "Epoch: 843; Model Loss: 2.036771297454834\n",
      "Epoch: 844; Model Loss: 2.0365917682647705\n",
      "Epoch: 845; Model Loss: 2.036412239074707\n",
      "Epoch: 846; Model Loss: 2.0362331867218018\n",
      "Epoch: 847; Model Loss: 2.0360546112060547\n",
      "Epoch: 848; Model Loss: 2.0358760356903076\n",
      "Epoch: 849; Model Loss: 2.0356979370117188\n",
      "Epoch: 850; Model Loss: 2.03551983833313\n",
      "Epoch: 851; Model Loss: 2.035342216491699\n",
      "Epoch: 852; Model Loss: 2.0351650714874268\n",
      "Epoch: 853; Model Loss: 2.0349879264831543\n",
      "Epoch: 854; Model Loss: 2.034811019897461\n",
      "Epoch: 855; Model Loss: 2.034634590148926\n",
      "Epoch: 856; Model Loss: 2.0344581604003906\n",
      "Epoch: 857; Model Loss: 2.0342824459075928\n",
      "Epoch: 858; Model Loss: 2.034106731414795\n",
      "Epoch: 859; Model Loss: 2.0339314937591553\n",
      "Epoch: 860; Model Loss: 2.033756971359253\n",
      "Epoch: 861; Model Loss: 2.033582925796509\n",
      "Epoch: 862; Model Loss: 2.0334091186523438\n",
      "Epoch: 863; Model Loss: 2.0332353115081787\n",
      "Epoch: 864; Model Loss: 2.033062219619751\n",
      "Epoch: 865; Model Loss: 2.0328891277313232\n",
      "Epoch: 866; Model Loss: 2.0327162742614746\n",
      "Epoch: 867; Model Loss: 2.032543659210205\n",
      "Epoch: 868; Model Loss: 2.0323715209960938\n",
      "Epoch: 869; Model Loss: 2.0322000980377197\n",
      "Epoch: 870; Model Loss: 2.032029151916504\n",
      "Epoch: 871; Model Loss: 2.031858444213867\n",
      "Epoch: 872; Model Loss: 2.0316877365112305\n",
      "Epoch: 873; Model Loss: 2.031517744064331\n",
      "Epoch: 874; Model Loss: 2.0313479900360107\n",
      "Epoch: 875; Model Loss: 2.0311787128448486\n",
      "Epoch: 876; Model Loss: 2.0310096740722656\n",
      "Epoch: 877; Model Loss: 2.0308406352996826\n",
      "Epoch: 878; Model Loss: 2.030672073364258\n",
      "Epoch: 879; Model Loss: 2.030503511428833\n",
      "Epoch: 880; Model Loss: 2.0303354263305664\n",
      "Epoch: 881; Model Loss: 2.030167818069458\n",
      "Epoch: 882; Model Loss: 2.0300002098083496\n",
      "Epoch: 883; Model Loss: 2.0298333168029785\n",
      "Epoch: 884; Model Loss: 2.0296664237976074\n",
      "Epoch: 885; Model Loss: 2.0294997692108154\n",
      "Epoch: 886; Model Loss: 2.0293335914611816\n",
      "Epoch: 887; Model Loss: 2.029167652130127\n",
      "Epoch: 888; Model Loss: 2.0290019512176514\n",
      "Epoch: 889; Model Loss: 2.028836488723755\n",
      "Epoch: 890; Model Loss: 2.0286712646484375\n",
      "Epoch: 891; Model Loss: 2.0285065174102783\n",
      "Epoch: 892; Model Loss: 2.028341770172119\n",
      "Epoch: 893; Model Loss: 2.028177499771118\n",
      "Epoch: 894; Model Loss: 2.0280134677886963\n",
      "Epoch: 895; Model Loss: 2.0278499126434326\n",
      "Epoch: 896; Model Loss: 2.027686357498169\n",
      "Epoch: 897; Model Loss: 2.0275230407714844\n",
      "Epoch: 898; Model Loss: 2.027360677719116\n",
      "Epoch: 899; Model Loss: 2.0271990299224854\n",
      "Epoch: 900; Model Loss: 2.0270376205444336\n",
      "Epoch: 901; Model Loss: 2.026876449584961\n",
      "Epoch: 902; Model Loss: 2.0267159938812256\n",
      "Epoch: 903; Model Loss: 2.0265555381774902\n",
      "Epoch: 904; Model Loss: 2.026395320892334\n",
      "Epoch: 905; Model Loss: 2.026235818862915\n",
      "Epoch: 906; Model Loss: 2.0260767936706543\n",
      "Epoch: 907; Model Loss: 2.0259180068969727\n",
      "Epoch: 908; Model Loss: 2.02575945854187\n",
      "Epoch: 909; Model Loss: 2.0256011486053467\n",
      "Epoch: 910; Model Loss: 2.0254428386688232\n",
      "Epoch: 911; Model Loss: 2.025285005569458\n",
      "Epoch: 912; Model Loss: 2.025127410888672\n",
      "Epoch: 913; Model Loss: 2.024970054626465\n",
      "Epoch: 914; Model Loss: 2.024813175201416\n",
      "Epoch: 915; Model Loss: 2.0246567726135254\n",
      "Epoch: 916; Model Loss: 2.0245003700256348\n",
      "Epoch: 917; Model Loss: 2.0243449211120605\n",
      "Epoch: 918; Model Loss: 2.024188995361328\n",
      "Epoch: 919; Model Loss: 2.024033784866333\n",
      "Epoch: 920; Model Loss: 2.0238795280456543\n",
      "Epoch: 921; Model Loss: 2.0237252712249756\n",
      "Epoch: 922; Model Loss: 2.023571729660034\n",
      "Epoch: 923; Model Loss: 2.0234179496765137\n",
      "Epoch: 924; Model Loss: 2.0232651233673096\n",
      "Epoch: 925; Model Loss: 2.0231118202209473\n",
      "Epoch: 926; Model Loss: 2.0229592323303223\n",
      "Epoch: 927; Model Loss: 2.0228071212768555\n",
      "Epoch: 928; Model Loss: 2.0226545333862305\n",
      "Epoch: 929; Model Loss: 2.0225026607513428\n",
      "Epoch: 930; Model Loss: 2.0223512649536133\n",
      "Epoch: 931; Model Loss: 2.022200107574463\n",
      "Epoch: 932; Model Loss: 2.0220491886138916\n",
      "Epoch: 933; Model Loss: 2.0218982696533203\n",
      "Epoch: 934; Model Loss: 2.0217478275299072\n",
      "Epoch: 935; Model Loss: 2.0215976238250732\n",
      "Epoch: 936; Model Loss: 2.0214481353759766\n",
      "Epoch: 937; Model Loss: 2.021299123764038\n",
      "Epoch: 938; Model Loss: 2.0211503505706787\n",
      "Epoch: 939; Model Loss: 2.0210022926330566\n",
      "Epoch: 940; Model Loss: 2.0208539962768555\n",
      "Epoch: 941; Model Loss: 2.0207064151763916\n",
      "Epoch: 942; Model Loss: 2.0205588340759277\n",
      "Epoch: 943; Model Loss: 2.020411729812622\n",
      "Epoch: 944; Model Loss: 2.0202648639678955\n",
      "Epoch: 945; Model Loss: 2.020118236541748\n",
      "Epoch: 946; Model Loss: 2.0199718475341797\n",
      "Epoch: 947; Model Loss: 2.0198259353637695\n",
      "Epoch: 948; Model Loss: 2.0196802616119385\n",
      "Epoch: 949; Model Loss: 2.0195348262786865\n",
      "Epoch: 950; Model Loss: 2.0193896293640137\n",
      "Epoch: 951; Model Loss: 2.01924467086792\n",
      "Epoch: 952; Model Loss: 2.0191001892089844\n",
      "Epoch: 953; Model Loss: 2.018956184387207\n",
      "Epoch: 954; Model Loss: 2.0188121795654297\n",
      "Epoch: 955; Model Loss: 2.0186686515808105\n",
      "Epoch: 956; Model Loss: 2.0185253620147705\n",
      "Epoch: 957; Model Loss: 2.0183825492858887\n",
      "Epoch: 958; Model Loss: 2.018239974975586\n",
      "Epoch: 959; Model Loss: 2.018097400665283\n",
      "Epoch: 960; Model Loss: 2.0179555416107178\n",
      "Epoch: 961; Model Loss: 2.0178136825561523\n",
      "Epoch: 962; Model Loss: 2.017672300338745\n",
      "Epoch: 963; Model Loss: 2.017531156539917\n",
      "Epoch: 964; Model Loss: 2.017390489578247\n",
      "Epoch: 965; Model Loss: 2.0172500610351562\n",
      "Epoch: 966; Model Loss: 2.0171101093292236\n",
      "Epoch: 967; Model Loss: 2.01697039604187\n",
      "Epoch: 968; Model Loss: 2.0168306827545166\n",
      "Epoch: 969; Model Loss: 2.0166916847229004\n",
      "Epoch: 970; Model Loss: 2.0165531635284424\n",
      "Epoch: 971; Model Loss: 2.0164146423339844\n",
      "Epoch: 972; Model Loss: 2.0162763595581055\n",
      "Epoch: 973; Model Loss: 2.0161385536193848\n",
      "Epoch: 974; Model Loss: 2.0160012245178223\n",
      "Epoch: 975; Model Loss: 2.0158638954162598\n",
      "Epoch: 976; Model Loss: 2.0157272815704346\n",
      "Epoch: 977; Model Loss: 2.0155906677246094\n",
      "Epoch: 978; Model Loss: 2.0154545307159424\n",
      "Epoch: 979; Model Loss: 2.0153188705444336\n",
      "Epoch: 980; Model Loss: 2.015183210372925\n",
      "Epoch: 981; Model Loss: 2.0150482654571533\n",
      "Epoch: 982; Model Loss: 2.014913558959961\n",
      "Epoch: 983; Model Loss: 2.0147790908813477\n",
      "Epoch: 984; Model Loss: 2.0146450996398926\n",
      "Epoch: 985; Model Loss: 2.0145113468170166\n",
      "Epoch: 986; Model Loss: 2.014378070831299\n",
      "Epoch: 987; Model Loss: 2.0142452716827393\n",
      "Epoch: 988; Model Loss: 2.014113187789917\n",
      "Epoch: 989; Model Loss: 2.0139808654785156\n",
      "Epoch: 990; Model Loss: 2.0138494968414307\n",
      "Epoch: 991; Model Loss: 2.0137181282043457\n",
      "Epoch: 992; Model Loss: 2.013587236404419\n",
      "Epoch: 993; Model Loss: 2.0134565830230713\n",
      "Epoch: 994; Model Loss: 2.013326406478882\n",
      "Epoch: 995; Model Loss: 2.0131964683532715\n",
      "Epoch: 996; Model Loss: 2.0130670070648193\n",
      "Epoch: 997; Model Loss: 2.0129377841949463\n",
      "Epoch: 998; Model Loss: 2.0128087997436523\n",
      "Epoch: 999; Model Loss: 2.0126800537109375\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "lr = 0.01\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # DO FORWARD PASS\n",
    "    # Calculate first hidden layer outputs\n",
    "    H_1 = ((A_HAT @ X) @ W_0).relu()  # H_1 reduces feature vector space from 1433 -> 100\n",
    "\n",
    "    # Calculate Output from our 2-layer GCN\n",
    "    O = ((A_HAT @ H_1) @ W_1).relu()\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = CrossEntropyLoss()\n",
    "    model_loss = loss(O, Y_ONE_HOT)\n",
    "\n",
    "    print(f\"Epoch: {epoch}; Model Loss: {model_loss.item()}\")\n",
    "\n",
    "    W_0.grad = None\n",
    "    W_1.grad = None\n",
    "\n",
    "    # DO BACKWARD PASS\n",
    "    model_loss.backward()\n",
    "    W_0.data -= lr * W_0.grad\n",
    "    W_1.data -= lr * W_1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "780f284e0ebdf609724e48d6015990f26a433b2d11fcba8f8b08df791d1e6f9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
